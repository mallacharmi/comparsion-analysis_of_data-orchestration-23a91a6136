# ğŸ“Š Comparative Analysis of Data Orchestration Frameworks

### Apache Airflow â€¢ Prefect â€¢ Dagster â€¢ Local Python ETL

This project implements a unified ETL pipeline across four different execution environments:  
**Local Python Script, Apache Airflow, Prefect, and Dagster.**  
The goal is to compare how each framework handles workflow orchestration, logging, monitoring, and output consistency.

All four workflows use the **same ETL logic** defined in `etl/core.py` to maintain fairness in comparison.

---

## ğŸ“˜ 1. Project Overview

This project focuses on:

- Executing the **same ETL pipeline** across multiple orchestration tools
- Understanding **workflow execution differences**
- Observing **logging, monitoring, and UI capabilities**
- Comparing **final outputs of all tools**
- Automation behavior, retries, failure handling, and performance insights

The ETL includes:

âœ” Extract â†’ CSV reading  
âœ” Transform â†’ Filtering + cleaning  
âœ” Load â†’ Writing partitioned data

---

## ğŸ“‚ 2. Project Folder Structure

Comparative-Analysis-of-DataOrchestration-Frameworks/
â”‚
â”œâ”€â”€ airflow_project/ # Airflow DAG & configs
â”‚ â”œâ”€â”€ etl_airflow_dag.py
â”‚
â”œâ”€â”€ dagster_project/ # Dagster job
â”‚ â”œâ”€â”€ etl_dagster_job.py
â”‚
â”œâ”€â”€ prefect_project/ # Prefect flow
â”‚ â”œâ”€â”€ etl_prefect_flow.py
â”‚
â”œâ”€â”€ etl/ # Shared ETL logic
â”‚ â”œâ”€â”€ core.py
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ synthetic_events.csv # Input dataset
â”‚
â”œâ”€â”€ output_airflow/ # Output generated by Airflow
â”œâ”€â”€ output_dagster/ # Output generated by Dagster
â”œâ”€â”€ output_prefect/ # Output generated by Prefect
â”œâ”€â”€ output_local/ # Output from local script
â”‚
â”œâ”€â”€ report/ # Screenshots & documentation
â”‚
â”œâ”€â”€ compare_outputs.py # Script to check equality of all outputs
â”œâ”€â”€ run_local_etl.py # Local execution ETL file
â”œâ”€â”€ README.md # Documentation file
â”œâ”€â”€ .gitignore # Ignored logs + system files

---

## ğŸ”§ 3. Technology Stack

| Category              | Tools Used                       |
| --------------------- | -------------------------------- |
| Programming Language  | Python                           |
| Orchestration Tools   | Apache Airflow, Prefect, Dagster |
| Supporting Libraries  | Pandas, Pathlib, Logging         |
| Execution Environment | Local, Docker                    |
| Dataset               | synthetic_events.csv             |

---

## ğŸ§  4. ETL Architecture

+-----------+
| Extract | â†’ Read CSV input
+-----------+
â†“
+-----------+
| Transform | â†’ Filter rows, clean data
+-----------+
â†“
+-----------+
| Load | â†’ Save output to partitioned folders
+-----------+

All frameworks use the same ETL operations defined in `etl/core.py`.

---

# ğŸš€ 5. How to Run All Pipelines

---

## âœ… A. Run the ETL Locally

python run_local_etl.py

Output stored in:
output_local/

---

## âœ… B. Run Prefect Flow

**Run Prefect script:**
cd prefect_project
python etl_prefect_flow.py

**Start Prefect UI:**
prefect server start

Open UI â†’ http://127.0.0.1:4200

Output saved â†’ `output_prefect/`

---

## âœ… C. Run Dagster Job

Run job:
cd dagster_project
python etl_dagster_job.py

Start Dagster UI:
dagster dev

Open â†’ http://127.0.0.1:3000

Output saved â†’ `output_dagster/`

---

## âœ… D. Run Airflow DAG

Start services:
docker compose up

Open UI â†’ http://localhost:8080  
Run: **etl_airflow_dag**

Output saved â†’ `output_airflow/`

---

## ğŸ“ˆ 6. Output Comparison

Compare final outputs:
python compare_outputs.py

This script checks:

- Row count comparison
- Column comparison
- Data equality
- Content hash check

Expected output on success:
local vs airflow equal: True
local vs prefect equal: True
local vs dagster equal: True

---

## ğŸ–¼ 7. Screenshots Included

The folder `report/screenshots/` contains:

- Local ETL run screenshot
- Prefect run logs
- Prefect run summary
- Dagster execution timeline
- Dagster Launchpad config
- Dagster job overview
- Airflow task logs
- Airflow graph view
- Airflow run summary

These visuals help explain:

- Workflow execution
- Success/failure patterns
- Log tracking
- UI monitoring differences

---

# ğŸ“‘ 8. Key Findings

### ğŸ”¹ **Airflow**

- Best suited for production-level scheduling
- Strong UI for monitoring
- Heavy but very scalable

### ğŸ”¹ **Prefect**

- Easiest to write and debug
- Modern and Pythonic
- Very friendly for developers

### ğŸ”¹ **Dagster**

- Cleanest UI among all
- Strong asset-based architecture
- Excellent logging and lineage tracking

### ğŸ”¹ **Output Consistency**

All frameworks produced **identical outputs**, proving the ETL logic is consistent across tools.

---

# ğŸ 9. Conclusion

Each orchestration framework serves unique use cases:

| Feature               | Best Tool |
| --------------------- | --------- |
| Simplicity            | Prefect   |
| UI & Observability    | Dagster   |
| Enterprise Scheduling | Airflow   |

This project demonstrates how workflow orchestration differs across tools while achieving the same ETL results.

---

# ğŸ™Œ Author

**Malla Charmi**  
Aditya University  
Comparative Analysis of Data Orchestration Frameworks

---

# ğŸ“œ License

This project is created for academic and learning purposes.
