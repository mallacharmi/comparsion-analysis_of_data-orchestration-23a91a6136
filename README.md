# Comparative Analysis of Data Orchestration Frameworks

This project implements the same ETL pipeline using **Apache Airflow**, **Prefect**, and **Dagster**.  
All three orchestrators run identical ETL logic using a shared module (`etl/core.py`) to ensure **output parity**, **retry validation**, and **backfill functionality**.

---

# ğŸ“ Repository Structure
â”œâ”€â”€ airflow/ # Airflow DAG + Docker files
â”œâ”€â”€ prefect/ # Prefect flow implementation
â”œâ”€â”€ dagster/ # Dagster job implementation
â”œâ”€â”€ etl/ # Shared ETL logic for all orchestrators
â”œâ”€â”€ data/ # Input dataset synthetic_events.csv
â”œâ”€â”€ output_local/ # Local ETL output
â”œâ”€â”€ output_airflow/ # Airflow output
â”œâ”€â”€ output_prefect/ # Prefect output
â”œâ”€â”€ output_dagster/ # Dagster output
â”œâ”€â”€ compare_outputs.py # Script to check output equality
â”œâ”€â”€ README.md # Project overview
â”œâ”€â”€ COMPARISON.md # Detailed comparison of Airflow, Prefect, Dagster

---

# ğŸ§ª ETL Pipeline Overview

Each orchestrator runs the **same ETL logic**:

### âœ” **Extract**
Reads `synthetic_events.csv` into a DataFrame.

### âœ” **Transform**
- Removes blocked countries  
- Handles optional failure simulation  
- Cleans event fields  

### âœ” **Load**
Writes partitioned Parquet output:

output_path/date=YYYY-MM-DD/data.parquet

---

# ğŸš€ How to Run the Project

---

## 1ï¸âƒ£ Local ETL Run (No orchestrator)
python run_local_etl.py

Output stored in `output_local/`.

---

## 2ï¸âƒ£ Airflow Pipeline

### Start Airflow:

cd airflow
docker-compose up --build

Open UI â†’ http://localhost:8080  
Enable DAG â†’ **etl_airflow_dag**

### Trigger DAG:

airflow dags trigger etl_airflow_dag


### Backfill:

airflow dags backfill -s 2025-01-01 -e 2025-01-05 etl_airflow_dag

---

## 3ï¸âƒ£ Prefect Pipeline

Run the flow:

python prefect/etl_prefect_flow.py

Backfill:

python prefect/etl_prefect_flow.py --backfill 5

Optional:

prefect server start
---

## 4ï¸âƒ£ Dagster Pipeline

Start UI:

cd dagster
dagster dev


Open UI â†’ http://localhost:3000  
Run job â†’ **etl_dagster_job**

Backfill â†’ Use Dagster UI partitions or CLI:

dagster job backfill -j etl_dagster_job -p 2025-01-01

---

# ğŸ“Š Output Parity Check

Run:
python compare_outputs.py

Expected Result:
local vs airflow: True
local vs prefect: True
local vs dagster: True

---

# ğŸ“˜ Documentation Included

- **Root README.md** (this file)
- **COMPARISON.md** â†’ Detailed framework analysis
- **airflow/README.md**
- **prefect/README.md**
- **dagster/README.md**

---

# ğŸ‰ Final Notes

This project demonstrates:

- Workflow orchestration  
- Cross-framework ETL consistency  
- Retry logic  
- Backfill processing  
- Parquet data engineering  

You can directly run any orchestrator and reproduce identical outputs.
